{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from LatentPixel import LatentGPT2, LPixelForMLM, TGraph, LPixelForClassification\n",
    "from LatentPixel.training import ExpConfig\n",
    "from LatentPixel import get_glue_dataset, GLUE_META\n",
    "from LatentPixel import RenderConfig\n",
    "\n",
    "_ = TGraph.init_render(dpi=180, pixels_per_patch=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cola', ([LatentPixel.metrics.metrics.MC], 2)),\n",
       " ('sst2', ([LatentPixel.metrics.metrics.Accuracy], 2)),\n",
       " ('mrpc',\n",
       "  ([LatentPixel.metrics.metrics.Accuracy, LatentPixel.metrics.metrics.F1], 2)),\n",
       " ('stsb',\n",
       "  ([LatentPixel.metrics.metrics.PC, LatentPixel.metrics.metrics.SC], -1)),\n",
       " ('qqp',\n",
       "  ([LatentPixel.metrics.metrics.Accuracy, LatentPixel.metrics.metrics.F1], 2)),\n",
       " ('mnli', ([LatentPixel.metrics.metrics.Accuracy], 3)),\n",
       " ('qnli', ([LatentPixel.metrics.metrics.Accuracy], 2)),\n",
       " ('rte', ([LatentPixel.metrics.metrics.Accuracy], 2)),\n",
       " ('wnli', ([LatentPixel.metrics.metrics.Accuracy], 2))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLUE_META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExpConfig(model='LPixelForMLM', init_path='', backbone_path='', coder_path='', render_path='storage/pixel-base', checkpoint_path='storage/checkpoints', dataset_paths=[''], seed=42, exp_type='debug', task='lpixel_pretrain', stage=1, optim='AdamW', scheduler='CosineAnnealingLR', batch_size=256, sub_size=128, eval_batch_size=256, eval_num_batch=12, lr=1e-05, beta1=0.9, beta2=0.95, decay=0.01, momentum=0.95, clip=1.0, mask_ratio=0.25, mask_type='span', total_steps=4000, max_token=512, eval_freq=100, save_freq=1000, best_save_freq=100, test_gpu_usibility=False, dpi=120, font_size=8, pad_size=3, pixels_per_patch=16, compress_ratio=8, font_file='GoNotoCurrent.ttf', image_size=[3, 16, 8464], latent_size=[3, 16, 8464], torch_compile=False, dynamic_shape=False, mix_precision='no', half_precision=False, half_coder=False, gradient_checkpointing=False, num_gpu_per_node=1, num_node=2, mp_workers=4, shard_strategy='no', offload_to_cpu=False, backward_prefetch='pre', on_cpu=False, current_step=1, num_trained_tokens=0, shuffle_dataset=False, init=False, no_ckpt=False, no_log=False, _best_loss=1000000000.0, _best_loss_step=-1, _best_dev_loss=1000000000.0, _best_dev_loss_step=-1, _timestamp=None, _continued=False, _name=None, _epoch=1, _num_grad_acc_step=-1, _num_gpu=-1, _rank=-1, _world_size=-1, _device_id=-1, _local_world_size=-1, _render_config=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ExpConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/sc118/sc118/yintaotai/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/sc118/sc118/yintaotai/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/sc118/sc118/yintaotai/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loaders, metrics, num_labels = get_glue_dataset('mnli', sub_size=4, mp_workers=4, seed=42, render_config=RenderConfig(dpi=180, pixels_per_patch=24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid 1159225's current affinity mask: 1000000001\n",
      "pid 1159225's new affinity mask: ffffffffff\n",
      "pid 1159278's current affinity mask: 1000000001\n",
      "pid 1159278's new affinity mask: ffffffffff\n",
      "pid 1159162's current affinity mask: 1000000001\n",
      "pid 1159162's new affinity mask: ffffffffff\n",
      "pid 1159228's current affinity mask: 1000000001\n",
      "pid 1159228's new affinity mask: ffffffffff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = next(iter(dev_loaders[0]))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the coder from storage/SD2_VQGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at storage/checkpoints/HL_pixel_2/lpixel_pretrain/LPixelForMLM/20230801-164748/100000/backbone were not used when initializing PIXELForSequenceClassification: ['decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.mask_token', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.value.bias']\n",
      "- This IS expected if you are initializing PIXELForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PIXELForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PIXELForSequenceClassification were not initialized from the model checkpoint at storage/checkpoints/HL_pixel_2/lpixel_pretrain/LPixelForMLM/20230801-164748/100000/backbone and are newly initialized: ['pooler.linear.weight', 'classifier.weight', 'pooler.ln.bias', 'classifier.bias', 'pooler.linear.bias', 'pooler.ln.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete the decoder\n",
      "The decoder of the coder is deleted\n"
     ]
    }
   ],
   "source": [
    "model = LPixelForClassification(\n",
    "    coder_path='storage/SD2_VQGAN',\n",
    "    backbone_path='storage/checkpoints/HL_pixel_2/lpixel_pretrain/LPixelForMLM/20230801-164748/100000/backbone',\n",
    "    img_size=[3, 24, 12696],\n",
    "    latent_size=[4, 3, 12696 // 8],\n",
    "    num_labels=num_labels\n",
    ")\n",
    "model.delete_unused_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 24, 12696])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb._value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decoder of the coder is deleted\n"
     ]
    }
   ],
   "source": [
    "model.delete_unused_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc118/sc118/yintaotai/miniconda3/envs/pt2hfpy310/lib/python3.10/site-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    result = model(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0831)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3468, -0.8664, -0.2123],\n",
       "        [-0.2795, -0.8263, -0.2373],\n",
       "        [-0.3301, -0.8646, -0.1751],\n",
       "        [-0.2990, -0.8279, -0.1640]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.predcits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the coder from storage/SD2_VQGAN/\n"
     ]
    }
   ],
   "source": [
    "gpt = LatentGPT2(coder_path='storage/SD2_VQGAN/', backbone_path='storage/checkpoints/HL_gpt2_1/lpixel_pretrain/LatentGPT2/20230728-024648/2000/backbone', img_size=[3, 24, 24*529], latent_size=[4, 3, 3*529])\n",
    "# gpt.init_connection_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.backbone.wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 1, 0, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = TGraph.from_text(['this is a sentence' * 10, 'this is another sentence'])\n",
    "tg.init_patch_mask('rand')\n",
    "# r: TGraph = pixel(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc118/sc118/yintaotai/miniconda3/envs/pt2hfpy310/lib/python3.10/site-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tg.labels = torch.tensor([1, 1])\n",
    "r = pixel(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7561, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete the decoder\n"
     ]
    }
   ],
   "source": [
    "gpt.delete_unused_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss torch.Size([2, 4, 4, 2116])\n",
      "attention_mask torch.Size([2, 1, 4, 2116])\n"
     ]
    }
   ],
   "source": [
    "r = gpt(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-91.8794, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r._value.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 529])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single_label_classification'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel.backbone.config.problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc118/sc118/yintaotai/miniconda3/envs/pt2hfpy310/lib/python3.10/site-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = pixel.backbone.forward(pixel_values=latent._value, attention_mask=tg.attention_mask, labels=torch.tensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2557, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss torch.Size([1, 4, 4, 2116])\n",
      "attention_mask torch.Size([4, 2116])\n"
     ]
    }
   ],
   "source": [
    "tg = TGraph.from_text(['this is a sentence' * 10])\n",
    "tg.init_patch_mask('rand')\n",
    "r: TGraph = gpt(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the coder from testgptc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (up_blocks): ModuleList(\n",
       "      (0-1): 2 x UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.load_coder('testgptc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 16928])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(4, 768, kernel_size=(4, 4), stride=(4, 4), bias=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.backbone.in_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTranspose2d(768, 4, kernel_size=(4, 4), stride=(4, 4), bias=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.backbone.out_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTranspose2d(768, 4, kernel_size=(4, 4), stride=(4, 4), bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.backbone.out_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn([2, 4, 4, 4*529])\n",
    "test[0, :, :, 4*528:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = gpt.backbone.in_proj(test).flatten(2).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 529, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1[0, 528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768, 1, 529])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = test1.transpose(1, 2).unsqueeze(2)\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = gpt.backbone.out_proj(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4, 2116])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5434, -2.0241, -0.2671, -0.0388,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1755,  0.5449,  0.4494, -0.6084,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.7187,  0.1441,  0.4418, -0.7696,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.2200,  2.1017, -1.5394, -1.2013,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3[0, 2, :, 4*527:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/work/sc118/sc118/yintaotai/huggingface_cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24b292b20c7491a982fc8069f8d421f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.isotonic import check_increasing\n",
    "from scipy.stats import spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([25])\n",
    "y = torch.randn([25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35900236])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_regression(y.unsqueeze(1), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc118/sc118/yintaotai/miniconda3/envs/pt2hfpy310/lib/python3.10/site-packages/sklearn/isotonic.py:72: UserWarning: Confidence interval of the Spearman correlation coefficient spans zero. Determination of ``increasing`` may be suspect.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_increasing(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, y], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39mcorrcoef(x, y)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "z = torch.cat([x, y], 1)\n",
    "torch.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat([x.unsqueeze(0), x.unsqueeze(0)], 0)\n",
    "torch.corrcoef(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0737,  0.2292, -0.7755, -1.1825, -0.2974,  0.7446, -0.5225,  0.4524,\n",
       "          0.8721, -0.4253,  0.4445,  0.7918,  0.9407,  0.7764, -0.5844, -1.0665,\n",
       "          0.8239,  0.9631, -1.7365, -0.8120, -0.1938, -0.6648, -0.5479,  0.0563,\n",
       "          0.0155],\n",
       "        [ 1.0737,  0.2292, -0.7755, -1.1825, -0.2974,  0.7446, -0.5225,  0.4524,\n",
       "          0.8721, -0.4253,  0.4445,  0.7918,  0.9407,  0.7764, -0.5844, -1.0665,\n",
       "          0.8239,  0.9631, -1.7365, -0.8120, -0.1938, -0.6648, -0.5479,  0.0563,\n",
       "          0.0155]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0737,  0.2292, -0.7755, -1.1825, -0.2974,  0.7446, -0.5225,  0.4524,\n",
       "         0.8721, -0.4253,  0.4445,  0.7918,  0.9407,  0.7764, -0.5844, -1.0665,\n",
       "         0.8239,  0.9631, -1.7365, -0.8120, -0.1938, -0.6648, -0.5479,  0.0563,\n",
       "         0.0155])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2792307692307692"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(x.tolist(), y.tolist()).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([6, 4, 3, 1587])\n",
    "b = torch.randn([6, 3, 1587]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5463e-01, -5.1946e-01,  8.3427e-01,  ..., -3.4802e-02,\n",
       "           -4.8067e-01, -7.7102e-01],\n",
       "          [ 8.2560e-02, -4.2176e-02,  9.2452e-03,  ..., -1.1269e-01,\n",
       "            2.3402e-02,  5.5810e-01],\n",
       "          [-3.3604e-01,  6.0198e-01, -1.9294e-02,  ..., -4.7259e-01,\n",
       "            5.4446e-01,  4.8747e-02]],\n",
       "\n",
       "         [[ 1.0295e-01, -2.1744e+00, -3.6195e-01,  ..., -1.5480e-02,\n",
       "           -4.7069e-02, -1.1261e+00],\n",
       "          [ 1.8461e-01,  1.1367e+00, -1.0771e-02,  ..., -2.8918e-01,\n",
       "           -1.4733e+00,  1.7462e-01],\n",
       "          [-1.4952e+00,  3.9007e-01, -7.8901e-02,  ...,  6.1379e-01,\n",
       "           -1.7326e+00, -8.1790e-02]],\n",
       "\n",
       "         [[-1.4182e-01, -2.4000e-01, -1.3953e-01,  ..., -4.7799e-02,\n",
       "            7.3503e-01,  2.2638e+00],\n",
       "          [-1.0469e-01,  8.0707e-01,  1.0392e-02,  ...,  3.1664e-01,\n",
       "           -2.6168e-01, -9.5351e-01],\n",
       "          [-1.2184e-01, -1.0882e+00,  6.7330e-02,  ...,  3.5869e-01,\n",
       "            3.4718e+00,  5.0007e-02]],\n",
       "\n",
       "         [[-1.5519e-02,  1.6251e+00,  1.1109e-01,  ...,  3.8425e-02,\n",
       "           -4.3112e-01, -5.9632e-01],\n",
       "          [ 4.5866e-02, -2.0454e-01, -1.9555e-03,  ...,  1.5671e-01,\n",
       "            1.7637e-01,  9.8900e-01],\n",
       "          [ 2.8615e-01,  9.1292e-01, -1.6788e-01,  ..., -7.0709e-01,\n",
       "            8.4392e-01,  2.0426e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.5415e-01,  1.3969e-01,  2.6739e-01,  ...,  3.5549e-01,\n",
       "            2.0048e-01, -7.8259e-01],\n",
       "          [-6.4873e-01, -6.2068e-01,  8.4116e-02,  ...,  4.3865e+00,\n",
       "            1.8556e+00,  9.7983e-02],\n",
       "          [ 1.7711e-01, -5.9329e-02,  1.7497e-01,  ..., -4.5898e-02,\n",
       "           -4.8290e-01, -7.0070e-01]],\n",
       "\n",
       "         [[-1.2575e-01, -5.6555e-02, -1.5568e+00,  ..., -2.1456e-01,\n",
       "            1.2828e+00, -4.1267e-01],\n",
       "          [ 1.2258e+00,  3.1824e-01,  1.2998e-01,  ..., -9.9171e-01,\n",
       "            1.9199e+00,  7.5460e-01],\n",
       "          [ 4.2788e-01,  1.6287e-01,  9.7604e-02,  ...,  5.5014e-02,\n",
       "            1.0513e-01, -7.9290e-03]],\n",
       "\n",
       "         [[ 1.5781e-01, -6.9068e-01, -3.8265e-01,  ...,  1.6568e-02,\n",
       "           -2.1766e+00, -1.2397e+00],\n",
       "          [ 1.5144e+00,  3.4272e-01, -2.3415e-02,  ...,  3.8183e-01,\n",
       "           -1.4401e+00,  2.3467e-02],\n",
       "          [ 3.3178e-01, -9.3493e-02, -1.9826e-01,  ...,  3.9072e-02,\n",
       "            1.4015e-02, -5.4598e-01]],\n",
       "\n",
       "         [[ 1.5808e-02,  1.1419e-01, -9.5697e-01,  ..., -5.9844e-02,\n",
       "           -2.0344e-02, -1.7764e-01],\n",
       "          [-3.0670e-01,  7.5680e-01, -7.6152e-02,  ...,  3.0848e+00,\n",
       "            6.0204e-02,  4.7402e-01],\n",
       "          [ 4.9638e-02, -7.0354e-02, -1.0976e-01,  ...,  3.2145e-02,\n",
       "            4.9104e-01,  1.8224e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 9.0513e-02,  5.3248e-02,  1.0822e+00,  ...,  6.2876e-01,\n",
       "           -7.9728e-02, -1.4891e+00],\n",
       "          [-4.0359e-01, -4.7670e-01,  3.2389e-01,  ...,  4.1467e-01,\n",
       "            2.6868e+00,  8.7200e-01],\n",
       "          [ 1.3734e-01,  1.2493e+00,  4.4783e-01,  ...,  1.6972e-01,\n",
       "           -3.4441e+00, -4.7493e-03]],\n",
       "\n",
       "         [[ 3.7776e-01,  5.8515e-01, -1.6295e+00,  ...,  1.2202e-01,\n",
       "           -2.3503e+00, -4.4271e+00],\n",
       "          [-3.2750e-02,  3.2888e-01, -2.3288e-01,  ...,  3.6857e-01,\n",
       "           -2.6153e-02, -9.1996e-01],\n",
       "          [ 1.2682e-01,  2.8656e-01,  6.6563e-01,  ..., -1.1442e-01,\n",
       "            3.6930e+00,  5.2153e-02]],\n",
       "\n",
       "         [[-1.1174e-01,  5.5000e-01,  1.1007e+00,  ..., -2.2594e+00,\n",
       "            7.0963e-01, -1.2114e+00],\n",
       "          [ 3.2817e-01, -3.6853e-01, -7.9464e-02,  ...,  1.6846e-01,\n",
       "            8.3819e-01,  3.1528e-01],\n",
       "          [-8.1837e-02,  3.3098e-01,  8.5976e-03,  ...,  3.6152e-01,\n",
       "           -2.0576e+00, -4.7375e-03]],\n",
       "\n",
       "         [[-1.7633e-01, -3.9272e-03,  5.5063e-01,  ..., -3.9970e-01,\n",
       "           -4.0789e-01, -3.5602e+00],\n",
       "          [-1.6003e-01,  2.8882e-01, -8.3504e-01,  ..., -8.5046e-02,\n",
       "           -1.0640e+00,  2.3930e-01],\n",
       "          [-1.0961e+00,  4.7783e-02,  3.8724e-01,  ...,  1.3228e-01,\n",
       "            1.3433e+00,  2.4786e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.4865e-01, -7.3278e-01,  6.9046e-02,  ...,  3.8438e-01,\n",
       "           -5.7350e-01,  1.0118e+00],\n",
       "          [ 1.3800e-01, -2.6729e-02, -1.8969e-01,  ...,  1.2007e-01,\n",
       "            1.3033e-01, -4.0111e-01],\n",
       "          [ 2.0876e+00,  6.0521e-03, -4.3813e-01,  ...,  8.6263e-02,\n",
       "            6.8597e-01,  1.3640e-01]],\n",
       "\n",
       "         [[ 1.4722e+00,  6.5381e-01, -2.1000e-01,  ..., -1.2593e-01,\n",
       "           -1.2533e+00, -5.9536e-01],\n",
       "          [-1.8103e-01,  4.2912e-02,  2.1638e-01,  ..., -1.8226e-01,\n",
       "           -1.6059e+00,  1.9157e-02],\n",
       "          [ 1.0590e+00, -4.8043e-02,  1.6311e+00,  ...,  5.3229e-01,\n",
       "           -6.8357e-01, -1.4591e-01]],\n",
       "\n",
       "         [[ 6.7384e-01,  3.5932e-01, -8.4728e-02,  ..., -1.9350e-01,\n",
       "           -8.3864e-02, -2.4546e+00],\n",
       "          [ 2.2694e-01,  3.8651e-02, -5.8878e-01,  ...,  2.7348e-02,\n",
       "            9.7702e-01, -5.0439e-01],\n",
       "          [-6.6268e-01,  8.8608e-02, -8.4778e-01,  ...,  9.7247e-01,\n",
       "           -4.2433e-01,  3.3981e-01]],\n",
       "\n",
       "         [[ 3.9524e-01,  1.3691e-01, -9.7339e-02,  ...,  5.0302e-01,\n",
       "            2.7614e-01,  5.0206e-01],\n",
       "          [-3.9736e-01,  1.0854e-01, -1.2246e+00,  ...,  1.6672e-01,\n",
       "           -9.3421e-01,  1.4570e+00],\n",
       "          [ 1.7415e+00,  4.2799e-02, -8.4741e-01,  ..., -5.1020e-01,\n",
       "            1.4876e+00,  2.4076e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.8255e-01, -1.9857e+00,  4.3259e-01,  ..., -1.0119e+00,\n",
       "            2.0113e-01, -6.6908e-01],\n",
       "          [-7.0169e-01,  2.5738e-01,  3.3688e-01,  ...,  6.4100e-01,\n",
       "           -1.4138e+00,  3.5884e-02],\n",
       "          [ 1.9550e-02,  3.8061e-01, -1.6806e-02,  ..., -6.6989e-01,\n",
       "           -4.1194e-01,  2.1207e-02]],\n",
       "\n",
       "         [[-1.4049e+00, -1.3178e+00, -4.5775e-01,  ...,  1.0159e+00,\n",
       "            6.2363e-02,  1.4402e+00],\n",
       "          [ 1.8317e-01, -2.2604e-01, -8.9991e-02,  ..., -2.3117e-01,\n",
       "            4.5962e+00, -1.5599e-01],\n",
       "          [ 1.0475e-01,  1.0627e-01,  1.2664e-01,  ..., -9.0568e-01,\n",
       "           -5.1189e-01, -5.0138e-02]],\n",
       "\n",
       "         [[-1.2455e+00,  5.6053e-01, -1.4846e-01,  ..., -1.0085e+00,\n",
       "           -3.1928e-02,  8.2250e-01],\n",
       "          [ 2.0192e-01, -1.9203e-01, -1.0640e-01,  ...,  4.1531e-01,\n",
       "           -2.5343e+00,  5.9794e-02],\n",
       "          [ 4.6294e-02,  3.3345e-01, -2.6102e-01,  ...,  1.5106e+00,\n",
       "            1.2346e+00,  2.8389e-02]],\n",
       "\n",
       "         [[-2.3022e-01, -3.0415e-01, -1.7133e-01,  ..., -1.5619e-01,\n",
       "           -8.6720e-02,  1.0960e+00],\n",
       "          [-1.0342e+00, -9.1730e-01, -8.2470e-01,  ...,  7.9231e-01,\n",
       "            6.8368e-01,  1.1428e-02],\n",
       "          [ 1.6509e-01, -1.5731e+00, -8.1102e-02,  ..., -4.4894e-01,\n",
       "            4.9537e-01, -6.9967e-02]]],\n",
       "\n",
       "\n",
       "        [[[-4.4818e-01, -1.5015e-01,  4.4525e-01,  ...,  1.5056e+00,\n",
       "           -3.3249e-02,  8.5404e-01],\n",
       "          [ 1.1869e+00, -1.2536e-01,  5.1478e-02,  ..., -1.0610e+00,\n",
       "           -9.4924e-03,  1.1743e+00],\n",
       "          [-5.3699e-02,  6.9694e-01,  5.6378e-01,  ...,  1.0772e+00,\n",
       "           -6.1769e-01, -4.3417e-01]],\n",
       "\n",
       "         [[ 6.5429e-02,  9.5335e-02, -5.1379e-01,  ..., -1.0001e+00,\n",
       "           -7.4942e-03,  4.1794e-01],\n",
       "          [ 2.2224e-01, -1.9588e-01, -1.0224e+00,  ..., -5.6609e+00,\n",
       "           -8.6627e-02,  1.2841e-01],\n",
       "          [ 2.0290e-01,  3.6686e-01, -3.3525e-01,  ..., -1.5684e+00,\n",
       "            8.4984e-01,  3.5877e-01]],\n",
       "\n",
       "         [[-5.3345e-02, -1.9688e-01, -3.9365e-02,  ..., -2.4410e-01,\n",
       "           -3.6768e-02,  3.0031e-01],\n",
       "          [-9.3828e-03,  1.8735e-02, -8.7522e-01,  ...,  9.5621e-01,\n",
       "            1.4789e-01,  1.4287e+00],\n",
       "          [ 6.6947e-03,  2.3964e-01, -1.2253e+00,  ...,  2.5685e+00,\n",
       "            3.2405e+00,  1.3643e+00]],\n",
       "\n",
       "         [[ 2.7841e-02,  2.6648e-01, -9.1669e-01,  ..., -2.6992e-01,\n",
       "            7.4454e-03,  1.2802e+00],\n",
       "          [ 5.8983e-01,  2.6549e-02,  5.0273e-01,  ..., -9.4600e-01,\n",
       "            1.4391e-01,  3.1251e+00],\n",
       "          [ 1.2757e-01, -5.8874e-02,  1.7532e+00,  ..., -1.8333e+00,\n",
       "           -2.6257e+00,  3.4146e-01]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, interleave_datasets, load_from_disk\n",
    "from datasets.distributed import split_dataset_by_node\n",
    "from collections import defaultdict\n",
    "\n",
    "from LatentPixel import TGraph, RenderConfig, get_glue_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_glue(batch: dict) -> TGraph:\n",
    "    merged = defaultdict(list)\n",
    "    for sample in batch:\n",
    "        for k, v in sample.items():\n",
    "            merged[k].append(v)\n",
    "    batch = merged\n",
    "    label = batch['label']\n",
    "    if len(batch) == 4:\n",
    "        keys = list(batch.keys())\n",
    "        text = list(zip(batch[keys[0]], batch[keys[1]]))\n",
    "    elif len(batch) == 3:\n",
    "        key = list(batch.keys())[0]\n",
    "        text = batch[key]\n",
    "    else:\n",
    "        raise ValueError(f'GLUE dataset should be 3 or 4 fields, but got {len(batch)} fields')\n",
    "    \n",
    "    tgraph = TGraph.from_text(text)\n",
    "    tgraph.labels = torch.tensor(label)\n",
    "    assert isinstance(tgraph.labels, torch.LongTensor) or isinstance(tgraph.labels, torch.DoubleTensor)\n",
    "    tgraph.attention_mask   # init the attention mask\n",
    "    \n",
    "    return tgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/sc118/sc118/yintaotai/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('glue', 'cola', split='train')\n",
    "data = split_dataset_by_node(data, 0, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data, batch_size=8, collate_fn=collate_glue, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1][1, 1, 1, 1, 1, 1, 1, 1][1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TGraph.from_text(list(zip(batch[list(batch.keys())[0]], batch[list(batch.keys())[1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAFwCAIAAAAue7doAAAM3klEQVR4nO3bb2hV9R/A8bMyNXRqV02nueXutDREY4ppmIVKhA8KLILMNAgSgooCMaPIggQ1kB4kWpaUkaY4wzCjBwoZqZURgaWk+IemaMuKzenm7v09uP0ua3NXp5/9pv1er0fee84993vP+fi+d/+KstlsQucpKipq1/6u17/b1T4P13T2AoB/j5igVFRUbNq0KeRQzY0dO/aLL764/ONUVFR8+umnHXTw1hoaGh5++OF+/fqVlpbW19d/9dVXI0eOTKVS8+bN64ini3I5J8QANHeVDkCM7D+9+uqrxcXFf/31V7Y90ul0VVVVux5yMbZu3VpTU1N4nz179nzzzTeF90mn05s3b76Eg1+a9957b8SIEadPn66vr89ms5WVlUuWLMlms7mbLXTK9TqvyzkhBqC5dg1AC5c5D53uH59Qmpqa3n777VGjRq1Zs6a9L6wj3HvvvalUqvA+S5cu/fbbbzvo4Jdm3759lZWV119/fffu3XM3J02alCRJ7mag2OvVcSfkkhmAq0/zumzcuLGysnLLli2jRo06b37S6fS6devGjBnTs2fPysrKL7/8Mn9/7g3q888/Hzt27IABAwYMGPDcc8/lt65Zs2bcuHE9evQYNmxY/q3sxIkTDz30UCqVGjBgwIIFC5qamlo/XVVVVSaTeemll0pLS1OpVDqdXrt2bX6HZ599tmvXrqlUqqys7K233iqwgNwb1M8//zx48OANGzY0X3Nbyzt69Oh9993Xu3fv8vLytWvXFhcXnzp1qvnyTpw4MWvWrIEDB/bu3XvGjBm//vprNptdsGBBKpXq0aNHWVnZwoULJ0+enCRJSUlJWVnZuXPnWp/Sjrhebb2ivLbOUv6E7N69e+rUqd26dfv6668NQIcOQAuXMw9Xgn8saOrUqStXrmxqaiotLc3PSnPpdHr06NGHDx9uaGhYunTpDTfckPvQmL82+/bt+/777zOZzMGDB3v27Ll9+/bc1ltvvXX//v1NTU0rVqwoLi5uaGjIZrOTJ0+eM2fO2bNnjx8/Pnz48DfffLP101VVVe3YsaOkpCR3LQ8dOlRdXd18n/Hjxy9fvjx/s60FbN68+cCBA6WlpR9++GHzgxdY3sSJE+fMmVNXV/fbb79Nnz49SZIW8zRlypSZM2f++eeftbW1c+fOHT16dCaTyWazzz///OzZs/O7devWrcBn8ssZoLauV1uv6IJnKX9CKioqPvnkkz/++KOxsdEAdOgAtPDvCcr+/fv79OlTW1ubzWZfe+21Rx55pPXe6XQ69z6QzWYzmczgwYPXrVuXbeNL6AkTJrz77ru5rcuWLcvdefbs2SRJDhw4cODAgSRJjh07lrv/9ddfnzRpUuunq6qq+uWXX3r16rV48eIWlzOnxTy1tYDVq1cPHTo0d7P5wdta3sGDB5Mkyc/url27WszT4cOHm+9QW1vbpUuXnTt3Zv9XQSlwvc77itpaQPOzlD8hixYtOu/OBiD/8KgBaOFqD0qX/MqWL19eW1tbVlaWJEljY+OZM2eWLVvWv3//Fi8gf09RUdHgwYOPHTvWfOuGDRveeeedU6dOFRUV7d27t6mpKXf/kCFDcv/o2rVrkiQNDQ0nT54sKiq64447cvc3NDTk92khnU7v3Llz0aJF5eXlDz744JIlS3r37t3W+W1rAS+88EJdXV3fvn3P+6jWy6upqbnuuutKSkpy95eWlrZ4yJEjR7p06ZLfoUePHv369Tt+/HhbCwtX+Hq1fkXNH9vWWcq75ZZb2npeA5DT6QNwZfo7KPX19atXr966dWt+kh5//PFVq1bNnz+/xQOqq6tz/8hms4cOHRo0aFB+086dOx977LFt27aNHz8+SZJx48blN11zTcufTw8cODBJkh9++KHAcOSNGDHi/fffr6mpmTVr1jPPPLN69er8pua/CFRgAa+88sqNN944e/bs7777rry8vMXxWy+vpKSksbHx5MmTuf8/NTU1LXYYNGjQuXPnqqurc2cg98H45ptvvuBrCXHB69X6FeUVOEt5BX69ygDkdO4AXLH+Po8fffTR0KFDp0yZctN/PfnkkytWrMhkMi0esHLlyqNHjyZJsmTJknPnzk2bNi2/6fjx47169RozZkySJLt27frxxx8LPPGwYcPuvPPOp59++vfff0+SpLq6et++fefd88iRI/v370+SJJVKjRw5sq6urvnW/v3779mzJ0mSTCZTYAGDBg164IEH5syZM2PGjDNnzlzwvJSXl48bN+7ll19ubGysr69fvHhx6x3uueeeefPm1dXV1dfXz58/v7KyctSoUYUPO3fu3C1btlzw2S/o4q9Xa+26TK0ZgPwOnTgAV6y/g7J8+fInnnii+Yb777//9OnTn332WYsHPProo9OnT+/Tp8/69es3b97cp0+f/Kbp06dPmzatoqJi4sSJH3zwwcyZMws/98aNG5MkGT58eHFx8d13393W/NXU1MyYMaNfv3433XTTTz/99MYbbzTf+uKLL+7YsaNv377Lli274AIWL17cvXv3p556qvDCcj7++OODBw8OHDjwtttuu/3221vvsH79+iRJhgwZMnTo0JMnT1ZVVRX4XJAkSSaT2b59e+6L88t08dertfZephYMQF4nDsCVq13fcUmn05s2beqQb+Zc2fbu3du1a9eL+bFfe3Xo9QpnADr6ia6ueWit3b96n73C/hip42zbti33Hcfa2tqFCxfedddd1157bWcvqvMZAArwx4Ft2r1794QJE3r16pVOpxsaGlatWtXZK+J/ygBcgqL/nzecK9PV/ufqxLra50FQgDC+5AHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQgjKEAYQQHCCAoQRlCAMIIChBEUIIygAGEEBQjzH0K1gH2XgMP+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=368x368>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.squarelize().to_PIL()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.attention_mask[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rconfig = RenderConfig()\n",
    "render = TGraph.init_render(**rconfig.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel.data.rendering.pangocairo_renderer.PangoCairoTextRenderer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TGraph.from_text([('this is a sentecne', 'another one'), ('this is a sentecne', 'another one')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=368x368>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.squarelize().to_PIL()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 8464, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ac8459000>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a.pixel_values[:, :300, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c44f36e446dbacec008653a856e66ff1e85db08dec5a7e40c028d54fc7a43cbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
